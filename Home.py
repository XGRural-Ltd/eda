import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import pickle
import kagglehub

from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.metrics import silhouette_score, davies_bouldin_score

#section = st.sidebar.radio("Selecione uma etapa da an√°lise:", (
    #"1. Vis√£o Geral dos Dados",
    #"2. An√°lise Univariada",
    #"3. Correla√ß√£o entre Vari√°veis",
    #"4. Detec√ß√£o de Outliers",
    #"5. Pr√©-processamento",
    #"6. Redu√ß√£o de Dimensionalidade",
    #"7. Clusteriza√ß√£o",
    #"8. Avalia√ß√£o dos Clusters"
#))

@st.cache_data
def load_data():
    path = kagglehub.dataset_download("maharshipandya/-spotify-tracks-dataset")
    path_dataset = path + '/dataset.csv'
    df = pd.read_csv(path_dataset, index_col=0)
    if 'track_genre' not in df.columns:
        df['track_genre'] = 'unknown'
    return df

df = load_data()

num_features = df.select_dtypes(include=['float64', 'int64']).columns.tolist()


def pagina_1_visao_geral(df):
    st.subheader("üìä Informa√ß√µes Gerais do Dataset")
    st.write("Nesta etapa vamos ficar mais familiarizados com os dados. Vamos explorar as colunas, tipos de dados, valores ausentes, estat√≠sticas descritivas e visualizar alguns plots.")

    num_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()
    

    st.markdown("**Visualize o DataFrame com as colunas selecionadas:**")
    cols = st.multiselect("Colunas para exibir:", df.columns.tolist(), default=df.columns[:6].tolist())
    st.dataframe(df[cols].head(15))

    
    st.markdown("**Tipos de dados e valores ausentes:**")
    if st.checkbox("Mostrar dtypes e valores nulos"):
        col1, col2 = st.columns(2)
        with col1:
            st.write(df.dtypes.astype(str))
        with col2:
            st.write(df.isnull().sum())

    st.markdown("**Estat√≠sticas descritivas:**")
    if st.checkbox("Exibir estat√≠sticas descritivas"):
        st.write(df.describe())

    st.markdown("---")
    st.subheader("üßæ Dicion√°rio de Dados: Descri√ß√£o das Colunas")

    col_descriptions = {
        "track_id": "O ID do Spotify para a faixa.",
        "artists": "Nomes dos artistas que performaram a faixa. Se houver mais de um, s√£o separados por ponto e v√≠rgula.",
        "album_name": "Nome do √°lbum no qual a faixa aparece.",
        "track_name": "Nome da faixa.",
        "popularity": "Popularidade da faixa (0 a 100), baseada em n√∫mero e rec√™ncia de reprodu√ß√µes.",
        "duration_ms": "Dura√ß√£o da faixa em milissegundos.",
        "explicit": "Indica se a faixa possui conte√∫do expl√≠cito (True = sim, False = n√£o).",
        "danceability": "Qu√£o dan√ßante √© a faixa, de 0.0 (menos) a 1.0 (mais dan√ßante).",
        "energy": "Energia percebida da faixa, de 0.0 a 1.0.",
        "key": "Tom da m√∫sica (0 = D√≥, 1 = D√≥‚ôØ/R√©‚ô≠, ..., -1 = indetect√°vel).",
        "loudness": "Volume geral da faixa em decib√©is (dB).",
        "mode": "Modalidade: 1 = maior, 0 = menor.",
        "speechiness": "Detecta presen√ßa de fala. 1.0 = fala pura; 0.0 = m√∫sica pura.",
        "acousticness": "Confian√ßa de que a faixa √© ac√∫stica (0.0 a 1.0).",
        "instrumentalness": "Probabilidade de n√£o conter vocais. Pr√≥ximo de 1.0 = instrumental.",
        "liveness": "Probabilidade de ter sido gravada ao vivo. Acima de 0.8 = performance ao vivo.",
        "valence": "Qu√£o positiva √© a m√∫sica (0.0 = triste, 1.0 = alegre).",
        "tempo": "Tempo estimado da faixa (batidas por minuto).",
        "time_signature": "Compasso estimado (de 3 a 7).",
        "track_genre": "G√™nero musical da faixa."
    }

    available_columns = list(col_descriptions.keys())
    selected_columns = st.multiselect("Selecione as colunas que deseja entender melhor:", available_columns)

    if selected_columns:
        for col in selected_columns:
            st.markdown(f"**üîπ {col}**: {col_descriptions[col]}")
    
    st.markdown("---")
    st.subheader("üìà Visualiza√ß√µes Gerais de Distribui√ß√£o")

    selected_col = st.selectbox("Selecione uma coluna num√©rica:", num_cols)
    plot_type = st.radio("Tipo de gr√°fico:", ["Histograma", "Boxplot", "Ambos"])

    fig, axs = plt.subplots(1, 2 if plot_type == "Ambos" else 1, figsize=(14, 4))
    if plot_type == "Histograma" or plot_type == "Ambos":
        ax = axs[0] if plot_type == "Ambos" else axs
        sns.histplot(df[selected_col], kde=True, ax=ax, color='skyblue')
        ax.set_title(f"Histograma de {selected_col}")
    if plot_type == "Boxplot" or plot_type == "Ambos":
        ax = axs[1] if plot_type == "Ambos" else axs
        sns.boxplot(x=df[selected_col], ax=ax, color='salmon')
        ax.set_title(f"Boxplot de {selected_col}")
    st.pyplot(fig)

    st.markdown("---")
    st.subheader("üìà Gr√°ficos de Dispers√£o entre Vari√°veis Num√©ricas")
    x_axis = st.selectbox("Vari√°vel no eixo X:", num_features, index=0)
    y_axis = st.selectbox("Vari√°vel no eixo Y:", num_features, index=1)
    show_trend = st.checkbox("Mostrar linha de tend√™ncia (regress√£o linear)")
    

    df_plot = df[[x_axis, y_axis]].dropna()

    fig, ax = plt.subplots()
    if show_trend:
        sns.regplot(data=df_plot, x=x_axis, y=y_axis, ax=ax,
                    scatter_kws={'alpha': 0.5, 'color': 'red'},
                    line_kws={"color": "blue"})
    else:
        sns.scatterplot(data=df_plot, x=x_axis, y=y_axis, alpha=0.5, color='red', ax=ax)

    ax.set_title(f"Dispers√£o entre {x_axis} e {y_axis}")
    st.pyplot(fig)
    st.markdown("üìå Danceability vs. Energy")
    st.markdown("- J√° esperamnos uma correla√ß√£o positiva entre 'danceability' e 'energy', pois m√∫sicas mais dan√ßantes tendem a ter mais energia.  \n"
                "- A linha de tend√™ncia (regress√£o linear) ajuda a visualizar uma correla√ß√£o moderadamente positiva. \n"
                "\n" 
                "üìå Acousticness vs. Energy \n"
                "- Correla√ß√£o negativa forte esperada, pois m√∫sicas ac√∫sticas s√£o menos energ√©ticas \n"
                "- A linha de tend√™ncia decrescemte indica uma rela√ß√£o inversamente proporcional. \n"
                "\n"
                "üìå Loudness vs. Energy \n"
                "- Baixa dispers√£o e ascend√™ncia dos pontos mostram uma correla√ß√£o fortemente positiva (m√∫sicas energ√©ticas costumam ser mais altas) \n")

def pagina_2_analise_univariada(df):
    st.subheader("üî¨ An√°lise Univariada Detalhada")
    st.markdown("Explore a distribui√ß√£o de cada vari√°vel. Use os filtros para comparar diferentes g√™neros e ajuste os gr√°ficos para uma an√°lise mais profunda.")

    st.markdown("### üé≠ Comparar Distribui√ß√µes por G√™nero")
    genres_to_compare = st.multiselect(
        "Selecione um ou mais g√™neros para comparar (opcional):",
        sorted(df['track_genre'].unique().tolist())
    )

    if genres_to_compare:
        df_filtered = df[df['track_genre'].isin(genres_to_compare)]
        hue_on = 'track_genre'
    else:
        df_filtered = df.copy()
        hue_on = None

    st.markdown("### ‚öôÔ∏è Controles da An√°lise")
    selected_var = st.selectbox("Selecione uma vari√°vel num√©rica para an√°lise:", num_features)

    num_bins = st.slider("N√∫mero de Bins para o Histograma:", min_value=10, max_value=100, value=30)
    
    st.markdown(f"---\n### üéØ An√°lise da vari√°vel: `{selected_var}`")

    st.markdown("**üìä Visualiza√ß√£o da Distribui√ß√£o:**")
    col1, col2 = st.columns(2)
    with col1:
        fig1, ax1 = plt.subplots()
        sns.histplot(data=df_filtered, x=selected_var, hue=hue_on, kde=True, ax=ax1, bins=num_bins, palette='viridis')
        ax1.set_title(f"Distribui√ß√£o de {selected_var}")
        st.pyplot(fig1)

    with col2:
        fig2, ax2 = plt.subplots()
        sns.boxplot(data=df_filtered, x=selected_var, y=hue_on, ax=ax2, palette='viridis', orient='h')
        ax2.set_title(f"Boxplot de {selected_var}")
        st.pyplot(fig2)

    st.markdown(f"**üîé Estat√≠sticas e Outliers para `{selected_var}`**")
    if genres_to_compare:
        st.write("Estat√≠sticas descritivas por g√™nero selecionado:")
        st.write(df_filtered.groupby('track_genre')[selected_var].describe().T)
    else:
        st.write("Estat√≠sticas descritivas gerais:")
        st.write(df_filtered[selected_var].describe())
    
    if st.checkbox(f"Mostrar outliers (m√∫sicas com valores extremos) para '{selected_var}'"):
        q1 = df_filtered[selected_var].quantile(0.25)
        q3 = df_filtered[selected_var].quantile(0.75)
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr
        outliers = df_filtered[(df_filtered[selected_var] < lower_bound) | (df_filtered[selected_var] > upper_bound)]
        
        if outliers.empty:
            st.success("N√£o foram encontrados outliers com base no crit√©rio de 1.5 * IQR. ‚ú®")
        else:
            st.write(f"Foram encontrados **{len(outliers)}** outliers:")
            st.dataframe(outliers[['track_name', 'artists', 'track_genre', selected_var]].sort_values(by=selected_var, ascending=False))

def pagina_3_correlacao(df):
    st.subheader("‚ÜîÔ∏è An√°lise de Correla√ß√£o")
    st.markdown("Investigue a rela√ß√£o entre as vari√°veis. Use o filtro de g√™nero e o slider de intensidade para focar nas correla√ß√µes mais importantes.")
    
    st.markdown("### üéµ Filtrar por G√™nero")
    genre_list = ['Todos'] + sorted(df['track_genre'].unique().tolist())
    corr_genre = st.selectbox("Selecione um g√™nero para calcular a correla√ß√£o:", genre_list)

    if corr_genre == 'Todos':
        df_corr = df[num_features]
    else:
        df_corr = df[df['track_genre'] == corr_genre][num_features]
        st.info(f"Mostrando correla√ß√µes apenas para o g√™nero: **{corr_genre}**")

    st.markdown("### ‚öôÔ∏è Controles do Heatmap")
    corr_method = st.selectbox("M√©todo de correla√ß√£o:", ["pearson", "spearman", "kendall"])
    
    corr_threshold = st.slider("Ocultar no gr√°fico e na tabela correla√ß√µes com valor absoluto abaixo de:", 0.0, 1.0, 0.0, 0.05)
    
    if not df_corr.empty and len(df_corr) > 1:
        corr_matrix = df_corr.corr(method=corr_method)
        
        mask_upper = np.triu(np.ones_like(corr_matrix, dtype=bool))
        mask_threshold = np.abs(corr_matrix) < corr_threshold
        mask_heatmap = mask_upper | mask_threshold
        
        fig, ax = plt.subplots(figsize=(12, 9))
        sns.heatmap(corr_matrix, mask=mask_heatmap, annot=True, cmap='coolwarm', fmt=".2f", ax=ax, annot_kws={"size": 8}, vmin=-1, vmax=1)
        ax.set_title(f"Mapa de Calor (M√©todo: {corr_method.capitalize()}, G√™nero: {corr_genre})", fontsize=16)
        st.pyplot(fig)

        st.markdown("### ‚ú® Pares com Maior Correla√ß√£o")
        st.write(f"Abaixo est√£o os pares de vari√°veis com correla√ß√£o absoluta acima de **{corr_threshold}** (excluindo duplicatas e auto-correla√ß√µes).")
        
        mask_table = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)
        corr_unstacked = corr_matrix.where(mask_table).stack()
        
        strong_pairs = corr_unstacked.sort_values(key=abs, ascending=False)
        
        strong_pairs = strong_pairs[abs(strong_pairs) > corr_threshold]

        if strong_pairs.empty:
            st.warning("Nenhum par encontrado acima do threshold. Tente um valor menor.")
        else:
            st.dataframe(strong_pairs.to_frame(name='correlation_value').head(20))

    else:
        st.warning(f"N√£o h√° dados suficientes para o g√™nero '{corr_genre}' para calcular a correla√ß√£o.")

def pagina_4_outliers(df):
    st.subheader("üö® Detec√ß√£o de Outliers com Isolation Forest")
    st.markdown("""
    Nesta se√ß√£o, vamos identificar **outliers**: m√∫sicas que possuem caracter√≠sticas muito diferentes da maioria. Um outlier pode ser uma m√∫sica experimental, um erro nos dados ou simplesmente uma faixa √∫nica.
    
    Usaremos o algoritmo **Isolation Forest**, que √© eficiente em detectar anomalias em dados multidimensionais. Ele funciona isolando observa√ß√µes ao selecionar aleatoriamente uma feature e, em seguida, um valor de divis√£o aleat√≥rio entre os valores m√°ximo e m√≠nimo da feature selecionada.
    """)

    st.markdown("### ‚öôÔ∏è Controles da Detec√ß√£o")
    features_for_outliers = st.multiselect(
        "Selecione as features para a detec√ß√£o de outliers:", 
        num_features, 
        default=['danceability', 'energy', 'loudness', 'acousticness', 'valence']
    )
    
    if not features_for_outliers:
        st.warning("Por favor, selecione ao menos uma feature para a an√°lise.")
        return

    contamination = st.slider(
        "Taxa de contamina√ß√£o (propor√ß√£o de outliers):", 
        0.01, 0.2, 0.05, step=0.01,
        help="Este valor representa a propor√ß√£o esperada de outliers no dataset. Um valor maior resultar√° em mais m√∫sicas sendo classificadas como anomalias."
    )

    st.markdown("---")
    st.markdown("### üéº M√∫sicas An√¥malas Detectadas")

    df_outlier_analysis = df.copy()

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(df_outlier_analysis[features_for_outliers])

    iso = IsolationForest(contamination=contamination, random_state=42)
    df_outlier_analysis['anomaly'] = iso.fit_predict(X_scaled)
    outliers = df_outlier_analysis[df_outlier_analysis['anomaly'] == -1]

    st.write(f"Com base nas suas configura√ß√µes, foram detectadas **{len(outliers)}** m√∫sicas como outliers.")
    st.dataframe(outliers[['track_name', 'artists', 'track_genre'] + features_for_outliers])

    if len(features_for_outliers) >= 2:
        st.subheader("üìç Visualiza√ß√£o de Outliers em 2D (usando PCA)")
        st.markdown("""
        Para visualizar os outliers em um gr√°fico 2D, reduzimos a dimensionalidade das features selecionadas usando **An√°lise de Componentes Principais (PCA)**. Os pontos em vermelho representam as m√∫sicas marcadas como outliers.
        """)
        pca = PCA(n_components=2)
        X_pca = pca.fit_transform(X_scaled)
        
        df_pca = pd.DataFrame(X_pca, columns=['PC1', 'PC2'], index=df_outlier_analysis.index)
        df_pca['anomaly'] = df_outlier_analysis['anomaly']
        
        fig, ax = plt.subplots(figsize=(10, 7))
        sns.scatterplot(
            data=df_pca, x='PC1', y='PC2', hue='anomaly', 
            palette={1: 'blue', -1: 'red'}, style='anomaly',
            markers={1: '.', -1: 'X'}, s=100, alpha=0.7, ax=ax
        )
        ax.set_title("Outliers detectados via PCA")
        ax.legend(['Normal', 'Outlier'])
        st.pyplot(fig)
    else:
        st.info("Selecione 2 ou mais features para visualizar o gr√°fico de dispers√£o com PCA.")

@st.cache_data
def convert_df_to_csv(df):
    return df.to_csv(index=False).encode('utf-8')

def pagina_5_preprocessamento(df):
    st.subheader("‚öôÔ∏è 5. Pr√©-processamento dos Dados")
    st.markdown("""
    O pr√©-processamento √© uma etapa fundamental na prepara√ß√£o de dados para modelos de Machine Learning. Aqui, transformaremos nossas features para que os algoritmos possam interpret√°-las da melhor forma poss√≠vel.
    
    Vamos abordar duas etapas principais:
    1.  **Feature Scaling**: Padronizar as escalas das nossas vari√°veis num√©ricas.
    2.  **One-Hot Encoding**: Converter vari√°veis categ√≥ricas (como g√™nero musical) em um formato num√©rico que os modelos entendam.
    """)

    df_processed = df.copy()

    st.markdown("---")
    st.markdown("### 1. Feature Scaling (Padroniza√ß√£o)")
    st.markdown("""
    Algoritmos de clusteriza√ß√£o, como o K-Means, s√£o sens√≠veis √† escala das features. Vari√°veis com escalas maiores (como `duration_ms`) podem dominar o processo de agrupamento.
    Usaremos o **StandardScaler**, que transforma os dados para que tenham m√©dia 0 e desvio padr√£o 1.
    """)

    features_to_scale = st.multiselect(
        "Selecione as features num√©ricas para padronizar:",
        options=num_features,
        default=num_features
    )
    
    if features_to_scale:
        scaler = StandardScaler()
        df_processed[features_to_scale] = scaler.fit_transform(df_processed[features_to_scale])

        st.markdown("**Compara√ß√£o: Antes vs. Depois da Padroniza√ß√£o** (para a feature `danceability`)")
        col1, col2 = st.columns(2)
        with col1:
            st.write("Antes:")
            fig, ax = plt.subplots(figsize=(6,4))
            sns.histplot(df['danceability'], kde=True, ax=ax, color='blue')
            ax.set_title("Original")
            st.pyplot(fig)
        with col2:
            st.write("Depois:")
            fig, ax = plt.subplots(figsize=(6,4))
            sns.histplot(df_processed['danceability'], kde=True, ax=ax, color='green')
            ax.set_title("Padronizado")
            st.pyplot(fig)
    
    st.markdown("---")
    st.markdown("### 2. One-Hot Encoding para G√™neros")
    st.markdown("""
    Para usar a feature `track_genre` em nosso modelo, precisamos convert√™-la de texto para um formato num√©rico. O **One-Hot Encoding** cria novas colunas para cada g√™nero, marcando com `1` se a m√∫sica pertence √†quele g√™nero e `0` caso contr√°rio.
    """)
    
    if st.checkbox("Aplicar One-Hot Encoding na coluna 'track_genre'?", value=True):
        df_processed = pd.get_dummies(df_processed, columns=['track_genre'], prefix='genre')
        st.success(f"One-Hot Encoding aplicado! Novas colunas de g√™nero foram criadas.")
    
    st.markdown("---")
    st.markdown("### üèÅ DataFrame Final Pr√©-processado")
    st.markdown("Abaixo est√° uma amostra do nosso dataset ap√≥s as transforma√ß√µes. Este √© o conjunto de dados que usaremos para a clusteriza√ß√£o.")
    
    final_features = df_processed.select_dtypes(include=np.number).columns.tolist()
    final_df = df_processed[final_features]

    st.dataframe(final_df.head())
    st.write(f"O dataset final possui **{final_df.shape[0]}** linhas e **{final_df.shape[1]}** features.")

    st.markdown("### üíæ Baixar Dados Processados")
    st.markdown("Clique no bot√£o para baixar o DataFrame processado em um arquivo CSV para uso posterior.")
    
    csv = convert_df_to_csv(final_df)
    st.download_button(
       label="Baixar dados como CSV",
       data=csv,
       file_name='processed_spotify_data.csv',
       mime='text/csv',
    )
    if st.button("Salvar DataFrame em cache para pr√≥ximas etapas"):
        st.session_state['processed_df'] = final_df
        st.success("DataFrame processado salvo na sess√£o! ‚úÖ")


paginas = {
    "1. Vis√£o Geral dos Dados": pagina_1_visao_geral,
    "2. An√°lise Univariada": pagina_2_analise_univariada,
    "3. Correla√ß√£o entre Vari√°veis": pagina_3_correlacao,
    "4. Detec√ß√£o de Outliers": pagina_4_outliers,
    "5. Pr√©-processamento": pagina_5_preprocessamento
}

st.sidebar.title("üìä EDA TuneTAP")
escolha = st.sidebar.radio("Escolha uma etapa da an√°lise:", list(paginas.keys()))
paginas[escolha](df)
